#!/usr/bin/env python3
"""
Entrenador para PRODUCCIÃ“N con mejores hiperparÃ¡metros
Compatible 100% con Docker - Solo sklearn estÃ¡ndar
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import average_precision_score, precision_score, recall_score, f1_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler
import joblib
import os
import json
from datetime import datetime

def train_production_model(train_path, val_path, model_path, best_params):
    """
    Entrena modelo de PRODUCCIÃ“N con mejores hiperparÃ¡metros
    Compatible 100% con Docker
    """
    print("ğŸš€ ENTRENANDO MODELO DE PRODUCCIÃ“N")
    print("=" * 50)
    print(f"ğŸ¯ HiperparÃ¡metros optimizados: {best_params}")
    
    # Cargar datos
    print("ğŸ“Š Cargando datos...")
    train_df = pd.read_parquet(train_path)
    val_df = pd.read_parquet(val_path)
    
    print(f"âœ… Datos cargados:")
    print(f"   Train: {train_df.shape}")
    print(f"   Val: {val_df.shape}")
    
    # Preparar features y target
    drop_cols = ['comprado', 'customer_id', 'product_id']
    X_train = train_df.drop(columns=[col for col in drop_cols if col in train_df])
    y_train = train_df['comprado']
    X_val = val_df.drop(columns=[col for col in drop_cols if col in val_df])
    y_val = val_df['comprado']
    
    print(f"ğŸ“ˆ DistribuciÃ³n del target:")
    print(f"   Train: {np.bincount(y_train)} ({y_train.mean():.3f})")
    print(f"   Val: {np.bincount(y_val)} ({y_val.mean():.3f})")
    
    # PROCESAR WEEK FEATURE ANTES DEL PIPELINE (sin FunctionTransformer)
    if 'week' in X_train.columns:
        print("ğŸ“… Procesando feature 'week' sin FunctionTransformer...")
        X_train['week_of_year'] = pd.to_datetime(X_train['week']).dt.isocalendar().week
        X_val['week_of_year'] = pd.to_datetime(X_val['week']).dt.isocalendar().week
        X_train = X_train.drop('week', axis=1)
        X_val = X_val.drop('week', axis=1)
        print("âœ… Week procesado correctamente")
    
    # Detectar tipos de features automÃ¡ticamente
    numeric_feats = []
    categorical_feats = []
    
    for col in X_train.columns:
        if X_train[col].dtype in ['int64', 'float64']:
            numeric_feats.append(col)
        else:
            categorical_feats.append(col)
    
    print(f"ğŸ” Features detectadas:")
    print(f"   NumÃ©ricas ({len(numeric_feats)}): {numeric_feats}")
    print(f"   CategÃ³ricas ({len(categorical_feats)}): {categorical_feats}")
    
    # Pipeline de PRODUCCIÃ“N - Solo sklearn estÃ¡ndar
    transformers = []
    
    # Pipeline numÃ©rico: RobustScaler (equivalente a winsorizaciÃ³n + escalado)
    if numeric_feats:
        print("ğŸ”¢ Configurando pipeline numÃ©rico con RobustScaler...")
        num_pipeline = Pipeline([
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', RobustScaler())  # Maneja outliers automÃ¡ticamente
        ])
        transformers.append(('num', num_pipeline, numeric_feats))
    
    # Pipeline categÃ³rico: EstÃ¡ndar
    if categorical_feats:
        print("ğŸ“ Configurando pipeline categÃ³rico...")
        cat_pipeline = Pipeline([
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
        ])
        transformers.append(('cat', cat_pipeline, categorical_feats))
    
    # Preprocessor
    preprocessor = ColumnTransformer(
        transformers=transformers,
        remainder='drop'
    )
    
    # Clasificador con TUS mejores hiperparÃ¡metros
    print("ğŸ¤– Configurando RandomForest con hiperparÃ¡metros optimizados...")
    classifier = RandomForestClassifier(
        n_estimators=best_params['n_estimators'],      # 94
        max_depth=best_params['max_depth'],            # 17
        max_features=best_params['max_features'],      # None
        class_weight='balanced',
        random_state=42,
        n_jobs=-1,
        verbose=1  # Para ver progreso
    )
    
    # Pipeline completo
    model = Pipeline([
        ('preproc', preprocessor),
        ('clf', classifier)
    ])
    
    print("ğŸ”„ Entrenando modelo de producciÃ³n...")
    print("â³ Esto puede tomar varios minutos...")
    
    # Entrenar
    model.fit(X_train, y_train)
    
    print("âœ… Entrenamiento completado!")
    
    # Evaluar
    print("ğŸ“Š Evaluando modelo...")
    y_prob_train = model.predict_proba(X_train)[:, 1]
    y_prob_val = model.predict_proba(X_val)[:, 1]
    
    # Usar threshold optimizado (0.2 segÃºn anÃ¡lisis anterior)
    threshold = 0.2
    y_pred_train = (y_prob_train > threshold).astype(int)
    y_pred_val = (y_prob_val > threshold).astype(int)
    
    # MÃ©tricas en train
    ap_train = average_precision_score(y_train, y_prob_train)
    precision_train = precision_score(y_train, y_pred_train, zero_division=0)
    recall_train = recall_score(y_train, y_pred_train, zero_division=0)
    f1_train = f1_score(y_train, y_pred_train, zero_division=0)
    
    # MÃ©tricas en validaciÃ³n
    ap_val = average_precision_score(y_val, y_prob_val)
    precision_val = precision_score(y_val, y_pred_val, zero_division=0)
    recall_val = recall_score(y_val, y_pred_val, zero_division=0)
    f1_val = f1_score(y_val, y_pred_val, zero_division=0)
    
    print(f"ğŸ¯ RESULTADOS FINALES:")
    print(f"=" * 40)
    print(f"ğŸ“ˆ TRAIN:")
    print(f"   Average Precision: {ap_train:.4f}")
    print(f"   Precision: {precision_train:.4f}")
    print(f"   Recall: {recall_train:.4f}")
    print(f"   F1 Score: {f1_train:.4f}")
    
    print(f"ğŸ“Š VALIDATION:")
    print(f"   Average Precision: {ap_val:.4f}")
    print(f"   Precision: {precision_val:.4f}")
    print(f"   Recall: {recall_val:.4f}")
    print(f"   F1 Score: {f1_val:.4f}")
    
    print(f"ğŸ² PROBABILIDADES:")
    print(f"   Val Min: {y_prob_val.min():.4f}")
    print(f"   Val Max: {y_prob_val.max():.4f}")
    print(f"   Val Mean: {y_prob_val.mean():.4f}")
    print(f"   Val Median: {np.median(y_prob_val):.4f}")
    
    print(f"ğŸ¯ PREDICCIONES CON THRESHOLD {threshold}:")
    print(f"   Train positivas: {y_pred_train.sum():,}/{len(y_pred_train):,} ({y_pred_train.mean():.1%})")
    print(f"   Val positivas: {y_pred_val.sum():,}/{len(y_pred_val):,} ({y_pred_val.mean():.1%})")
    
    # Guardar modelo
    print(f"ğŸ’¾ Guardando modelo en: {model_path}")
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(model, model_path)
    
    # Verificar que se puede cargar
    print("ğŸ” Verificando modelo guardado...")
    try:
        test_model = joblib.load(model_path)
        test_pred = test_model.predict_proba(X_val[:5])
        print(f"âœ… Modelo verificado - Predicciones test: {test_pred[:, 1]}")
    except Exception as e:
        print(f"âŒ Error verificando modelo: {e}")
        return None
    
    # Guardar mÃ©tricas y metadatos
    results = {
        "timestamp": datetime.now().isoformat(),
        "experiment_name": "sodai_production_model",
        "hyperparameters": best_params,
        "train_metrics": {
            "average_precision": float(ap_train),
            "precision": float(precision_train),
            "recall": float(recall_train),
            "f1_score": float(f1_train)
        },
        "validation_metrics": {
            "average_precision": float(ap_val),
            "precision": float(precision_val),
            "recall": float(recall_val),
            "f1_score": float(f1_val)
        },
        "model_info": {
            "train_samples": len(X_train),
            "val_samples": len(X_val),
            "numeric_features": numeric_feats,
            "categorical_features": categorical_feats,
            "threshold_used": threshold,
            "positive_rate_train": float(y_pred_train.mean()),
            "positive_rate_val": float(y_pred_val.mean()),
            "probability_stats": {
                "min": float(y_prob_val.min()),
                "max": float(y_prob_val.max()),
                "mean": float(y_prob_val.mean()),
                "median": float(np.median(y_prob_val))
            },
            "production_ready": True,
            "docker_compatible": True
        }
    }
    
    results_path = os.path.join(os.path.dirname(model_path), "production_results.json")
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"ğŸ“‹ Resultados guardados en: {results_path}")
    print("ğŸ‰ Â¡MODELO DE PRODUCCIÃ“N LISTO!")
    
    return model_path, ap_val

if __name__ == "__main__":
    # HiperparÃ¡metros optimizados
    BEST_PARAMS = {
        'n_bins': 3,
        'winsor_lower': 3,
        'winsor_upper': 98,
        'n_estimators': 94,
        'max_depth': 17,
        'max_features': None
    }
    
    # Rutas - AJUSTA SEGÃšN TU ESTRUCTURA
    train_path = "/home/pvergara/Escritorio/laboratorio/dags/scripts/tmp/train.parquet"  # Cambia por tu ruta
    val_path = "/home/pvergara/Escritorio/laboratorio/dags/scripts/tmp/val.parquet"      # Cambia por tu ruta
    model_path = "outputs/models/sodai_production_model.pkl"
    
    print("ğŸ­ ENTRENADOR DE PRODUCCIÃ“N SODAI")
    print("=" * 50)
    print("âœ… HiperparÃ¡metros optimizados")
    print("âœ… Compatible con Docker")
    print("âœ… Solo sklearn estÃ¡ndar")
    print("âœ… RobustScaler (equivale a winsorizaciÃ³n)")
    print("âœ… Threshold optimizado (0.2)")
    
    # Verificar archivos
    if not os.path.exists(train_path):
        print(f"âŒ No se encuentra: {train_path}")
        print("ğŸ’¡ Ajusta las rutas en el script")
        exit(1)
    
    if not os.path.exists(val_path):
        print(f"âŒ No se encuentra: {val_path}")
        print("ğŸ’¡ Ajusta las rutas en el script")
        exit(1)
    
    # Entrenar
    result = train_production_model(train_path, val_path, model_path, BEST_PARAMS)
    
    if result:
        model_path, ap_val = result
        print(f"\nğŸ¯ MODELO DE PRODUCCIÃ“N COMPLETADO:")
        print(f"   ğŸ“ Archivo: {model_path}")
        print(f"   ğŸ“Š Average Precision: {ap_val:.4f}")
        print(f"   âœ… Compatible con Docker")
        print(f"   âœ… Listo para despliegue")
        
        print(f"\nğŸ“ PRÃ“XIMOS PASOS:")
        print(f"   1. cp {model_path} /ruta/app/models/model.pkl")
        print(f"   2. docker-compose restart backend")
        print(f"   3. python3 verify_model.py")
        print(f"   4. Â¡Probar con datos reales!")
        
    else:
        print("\nâŒ Error en el entrenamiento")